{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验介绍\n",
    "本实验是基于Keras+tensorflow（作为后端），已movie_lens 数据集为训练数据，进行电影评论数据的分类（预测评论是正面还是负面）的实验。\n",
    "# 实验步骤\n",
    "* 定义训练数据：下载movie_lens 数据集，keras库中已经包含了预处理好的数据集，此次未使用原始数据集，对数据进行预处理，已符合网络的输入结构\n",
    "* 定义层组成的网络：需要几层网络，每层网络的输出和输入维度，也就是将输入数据映射到多少维的空间中，网络相当于过滤器，会对数据进行层层萃取已获取输入数据的最合适的表现方式，本质上就是通过网络进行学习对应的参数\n",
    "* 配置学习过程：学习过程就是网络的目标是学习到输入数据的有用表达方式，这个获取这个表达方式的过程就是学习，为了更好的学习并达到目的，需要通过一些监控手段对学习过程进行监控，这里我们会使用损失函数来进行监控，损失函数是用于评估学习后的参数经过预测与目标值的偏差，这个偏差越小越好，为了更好的找到这个缩小偏差的方法，我们引入了优化器 优化器是通过损失函数的结果作为反馈信号，再通过优化器进行优化参数进行再次的训练已达到最终最小偏差为目的，优化器的实现机制是通过SDG随机梯度下降的方法来实现的。 因此我们需要在配置环境配置 损失函数，优化器，以及我们监控的指标 比如精度\n",
    "* 进行模型训练\n",
    "\n",
    "下来我们根据上面的步骤基于次实验场景进行具体训练和解说："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data,train_labels),(test_data,test_labels) = imdb.load_data(num_words = 10000)\n",
    "# 仅保留训练数据中前100000个最常出现的单词，低品词将被舍弃"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0] #查看第一个样本数据，这里存储的是经过索引后的数据，每个值代表当前词在字典中的索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0] #查看标签数据，0表示负面 1表示正面评论"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(sequence) for sequence in train_data]) # 查看整个训练数据集中 最大的索引数，因为限制了10000个常用词 所以大小为9999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下来我们将训练数据转换为英文看一下内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index is a dictionary mapping words to an integer index\n",
    "word_index = imdb.get_word_index()\n",
    "# We reverse it, mapping integer indices to words\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "# We decode the review; note that our indices were offset by 3\n",
    "# because 0, 1 and 2 are reserved indices for \"padding\", \"start of sequence\", and \"unknown\".\n",
    "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出train_data[0] 这个样本是正面的因此标签为1，数据是正常的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为上面的整数序列值不能直接输入到网络中，因此需要对数据先进行处理转换为张量，常用的方法有两种\n",
    "* 填充序列：使其具有相同的长度，再将列表转换为 (samples,word_indicies)的格式\n",
    "* 对列表进行one-hot 编码，将其转为0和1组成的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    # Create an all-zero matrix of shape (len(sequences), dimension)\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.  # set specific indices of results[i] to 1s\n",
    "    return results\n",
    "\n",
    "# Our vectorized training data\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# Our vectorized test data\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看一下向量话后的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到样本数据已经被做了编码，现在是有0，1数字组成的向量，下面对标签数据进行向量话，由于我们输出网络是介于0-1之间的值，同时42个分类的概率综合是1，所以对标签进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our vectorized labels\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建网络\n",
    "* 输入数据是向量，而标签是标量，这是一种常见的问题，这种类型的输入和输出非常使用使用带有relu 激活的全连接层（Dense）的简单堆叠。\n",
    "* 影响网络的另一个因素是Dense层的第一个参数，隐藏单元，这个代表 表示空间的维度，也就是将输入数据与W参数做点击然后投影到16维空间中，隐藏单元越多说明投影到更高维度，隐藏单元越多能够学到更复杂的表示，单网络计算代价也越大。\n",
    "对于该需求而言我们采用如下网络：\n",
    "* 两个中间层，都采用全连接层，同时使用relu来进行激活\n",
    "* 同时每层都有16个隐藏单元\n",
    "* 第三层输出一个标量，采用sigmoid 将输出的值压缩到[0，1] 之间的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下来我们对网络进行设置，需要设置包括优化器和损失函数：\n",
    "* 优化器 rmsprop ,用于根据损失函数的反馈信号更新参数\n",
    "* 损失函数 选择 binary_crosssentropy 二元交叉熵 ，用于评估训练后预测值与真实值间的变差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型训练\n",
    "模型训练时可以设置参数来进行模型训练阶段的调节，这里包括epoch 轮次，批量 batch_size \n",
    "* epoch 轮次，表示的是在全量数据训练的次数，比如下面是训练20次。\n",
    "* batch_size 批次，每次进行随机梯度下降计算的输入数据大小，每批的数据都是随机抽取的\n",
    "* learning_rate 也就是步长，表示每次梯度下降的长度，这个值越小需要更多的时间，太大可能会出现左右摆动的问题\n",
    "* 对于可能存在的局部最小点问题，是通过带有动量的SGD或者rmsprop的实现来解决"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.5125 - accuracy: 0.7863 - val_loss: 0.3974 - val_accuracy: 0.8576\n",
      "Epoch 2/20\n",
      "15000/15000 [==============================] - 1s 74us/step - loss: 0.3003 - accuracy: 0.9038 - val_loss: 0.3014 - val_accuracy: 0.8860\n",
      "Epoch 3/20\n",
      "15000/15000 [==============================] - 1s 75us/step - loss: 0.2177 - accuracy: 0.9277 - val_loss: 0.3396 - val_accuracy: 0.8593\n",
      "Epoch 4/20\n",
      "15000/15000 [==============================] - 1s 74us/step - loss: 0.1737 - accuracy: 0.9433 - val_loss: 0.2770 - val_accuracy: 0.8905\n",
      "Epoch 5/20\n",
      "15000/15000 [==============================] - 1s 75us/step - loss: 0.1376 - accuracy: 0.9566 - val_loss: 0.2845 - val_accuracy: 0.8880\n",
      "Epoch 6/20\n",
      "15000/15000 [==============================] - 1s 74us/step - loss: 0.1146 - accuracy: 0.9642 - val_loss: 0.3303 - val_accuracy: 0.8726\n",
      "Epoch 7/20\n",
      "15000/15000 [==============================] - 1s 79us/step - loss: 0.0925 - accuracy: 0.9732 - val_loss: 0.3149 - val_accuracy: 0.8812\n",
      "Epoch 8/20\n",
      "15000/15000 [==============================] - 1s 73us/step - loss: 0.0772 - accuracy: 0.9778 - val_loss: 0.3405 - val_accuracy: 0.8822\n",
      "Epoch 9/20\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0632 - accuracy: 0.9833 - val_loss: 0.4211 - val_accuracy: 0.8692\n",
      "Epoch 10/20\n",
      "15000/15000 [==============================] - 1s 73us/step - loss: 0.0513 - accuracy: 0.9867 - val_loss: 0.4115 - val_accuracy: 0.8759\n",
      "Epoch 11/20\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0433 - accuracy: 0.9886 - val_loss: 0.4179 - val_accuracy: 0.8746\n",
      "Epoch 12/20\n",
      "15000/15000 [==============================] - 1s 73us/step - loss: 0.0331 - accuracy: 0.9926 - val_loss: 0.4538 - val_accuracy: 0.8704\n",
      "Epoch 13/20\n",
      "15000/15000 [==============================] - 1s 73us/step - loss: 0.0303 - accuracy: 0.9928 - val_loss: 0.4789 - val_accuracy: 0.8729\n",
      "Epoch 14/20\n",
      "15000/15000 [==============================] - 1s 74us/step - loss: 0.0203 - accuracy: 0.9963 - val_loss: 0.5260 - val_accuracy: 0.8707\n",
      "Epoch 15/20\n",
      "15000/15000 [==============================] - 1s 74us/step - loss: 0.0165 - accuracy: 0.9983 - val_loss: 0.5564 - val_accuracy: 0.8700\n",
      "Epoch 16/20\n",
      "15000/15000 [==============================] - 1s 76us/step - loss: 0.0153 - accuracy: 0.9974 - val_loss: 0.5768 - val_accuracy: 0.8698\n",
      "Epoch 17/20\n",
      "15000/15000 [==============================] - 1s 74us/step - loss: 0.0110 - accuracy: 0.9985 - val_loss: 0.6090 - val_accuracy: 0.8695\n",
      "Epoch 18/20\n",
      "15000/15000 [==============================] - 1s 73us/step - loss: 0.0063 - accuracy: 0.9998 - val_loss: 0.6539 - val_accuracy: 0.8629\n",
      "Epoch 19/20\n",
      "15000/15000 [==============================] - 1s 73us/step - loss: 0.0092 - accuracy: 0.9983 - val_loss: 0.6847 - val_accuracy: 0.8669\n",
      "Epoch 20/20\n",
      "15000/15000 [==============================] - 1s 73us/step - loss: 0.0035 - accuracy: 0.9999 - val_loss: 0.7203 - val_accuracy: 0.8643\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型评估于优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "history 中包含了训练过程中的数据，可以通过history来查看训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.3.3-cp36-cp36m-manylinux1_x86_64.whl (11.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.6 MB 8.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.18.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (7.0.0)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 79.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.14.0)\n",
      "Installing collected packages: cycler, kiwisolver, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.3.1 matplotlib-3.3.3\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下来我们通过maplotlib 库绘制一下，模型训练过程中，精度，损失 在训练数据和验证数据的变化，同这个来评估模型的效果，\n",
    "* 我们构建一个已轮次为X轴\n",
    "* 已训练数据损失和验证数据损失 为Y轴\n",
    "* 用于观察训练阶段和验证阶段在不同轮次上的变化趋势"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"  训练损失\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"  验证损失\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由上图可以观察到以下信息：\n",
    "* 轮次在2.5 以后，训练损失随着轮次的增加逐渐减小\n",
    "* 轮次在2.5以后，验证损失随着轮次的增加逐渐增大\n",
    "这种在训练阶段表现很高，但是在验证数据表现差的场景，教过模型的过拟合，也就是说模型在新鲜数据上表现要差于训练阶段。 过拟合产生的原因由多种\n",
    "* 本例子关注因为训练轮次的变化产生的过拟合问题\n",
    "* 当然还包括数据的影响，因为在训练阶段数据的个性化不足，导致训练出的模型无法泛化到新数据上而引起过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "绘制训练阶段和雁阵阶段的精度趋势"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "acc_values = history_dict['accuracy']\n",
    "val_acc_values = history_dict['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由上图可以观察到以下信息：\n",
    "* 轮次在2.5 以后，训练精度在不断提高\n",
    "* 验证损失2.5 以后 出现下降，5以后基本出于逐渐下降的趋势\n",
    "原因同上面的分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "如上面的分析我们可以看到轮次在大概4以后，模型的精度一直出于下降，因此我们可以优化轮次为4再进行训练（这里的轮次就是超参数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 1s 44us/step - loss: 0.4483 - accuracy: 0.8242\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 1s 41us/step - loss: 0.2575 - accuracy: 0.9090\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 1s 41us/step - loss: 0.2004 - accuracy: 0.9282\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 1s 41us/step - loss: 0.1683 - accuracy: 0.9395\n",
      "25000/25000 [==============================] - 2s 67us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.30169105003356933, 0.8808000087738037]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面是在侧数据上的损失和精度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27590933],\n",
       "       [0.9999838 ],\n",
       "       [0.94255143],\n",
       "       ...,\n",
       "       [0.16744263],\n",
       "       [0.09262326],\n",
       "       [0.66663593]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验：进一步测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 尝试使用具有更多隐藏单位或更少隐藏单位的图层：32 个单位，64 个单位...\n",
    "* 尝试使用 mse 损失函数而不是 binary_crossentropy。\n",
    "* 尝试使用 tanh 激活（神经网络早期流行的激活）而不是 relu。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用64个单元 \n",
    "也就是将输入映射到64维的张量来表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.4632 - accuracy: 0.8292 - val_loss: 0.3294 - val_accuracy: 0.8826\n",
      "Epoch 2/4\n",
      "15000/15000 [==============================] - 1s 61us/step - loss: 0.2485 - accuracy: 0.9121 - val_loss: 0.2731 - val_accuracy: 0.8928\n",
      "Epoch 3/4\n",
      "15000/15000 [==============================] - 1s 60us/step - loss: 0.1807 - accuracy: 0.9351 - val_loss: 0.2767 - val_accuracy: 0.8902\n",
      "Epoch 4/4\n",
      "15000/15000 [==============================] - 1s 60us/step - loss: 0.1421 - accuracy: 0.9509 - val_loss: 0.2941 - val_accuracy: 0.8867\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(8, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(8, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=4,\n",
    "                    batch_size=128,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 2s 61us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.31359747153759004, 0.8774799704551697]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 16 维 0.30169105003356933, 0.8808000087738037\n",
    "* 64 维 之前是 , 通过增加神经单元的个数也就是投射的维度，模型在测试集上的效果反而变差了。 [0.3028281346178055, 0.8791999816894531]\n",
    "* 8 维 [0.2921900947189331, 0.8834800124168396]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "减小batch-size 试一下，从512 调整为128后效果有所下降  [0.31359747153759004, 0.8774799704551697]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用MSE作为损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "15000/15000 [==============================] - 1s 84us/step - loss: 0.0131 - accuracy: 0.9863 - val_loss: 0.0984 - val_accuracy: 0.8731\n",
      "Epoch 2/4\n",
      "15000/15000 [==============================] - 1s 79us/step - loss: 0.0100 - accuracy: 0.9911 - val_loss: 0.1021 - val_accuracy: 0.8724\n",
      "Epoch 3/4\n",
      "15000/15000 [==============================] - 1s 78us/step - loss: 0.0082 - accuracy: 0.9935 - val_loss: 0.1022 - val_accuracy: 0.8718\n",
      "Epoch 4/4\n",
      "15000/15000 [==============================] - 1s 79us/step - loss: 0.0069 - accuracy: 0.9943 - val_loss: 0.1057 - val_accuracy: 0.8678\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=4,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 59us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11349301282286645, 0.8547999858856201]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从测试效果看，使用MSE作为损失函数后，测试集上的精度下降了0.04个百分点，说明mse 不如 二分类交叉熵效果好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用tanh作为激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown loss function:tanh",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-2689ba65ddd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.compile(optimizer='rmsprop',\n\u001b[1;32m      2\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tanh'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m               metrics=['accuracy'])\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m history = model.fit(partial_x_train,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# Prepare list of loss functions, same size as model outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         self.loss_functions = training_utils.prepare_loss_functions(\n\u001b[0;32m--> 119\u001b[0;31m             self.loss, self.output_names)\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mprepare_loss_functions\u001b[0;34m(loss, output_names)\u001b[0m\n\u001b[1;32m    820\u001b[0m             \u001b[0mloss_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_loss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m         \u001b[0mloss_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_loss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    820\u001b[0m             \u001b[0mloss_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_loss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m         \u001b[0mloss_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_loss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mget_loss_function\u001b[0;34m(loss)\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;31m# Wrap loss function with signature `(y_true, y_pred, **kwargs)`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0;31m# in `LossFunctionWrapper` class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m     \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m     \u001b[0;31m# For losses which are given as strings/functions in the compile API,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/losses.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    793\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[0midentifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/losses.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(name, custom_objects)\u001b[0m\n\u001b[1;32m    774\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m                                     printable_module_name='loss function')\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 raise ValueError('Unknown ' + printable_module_name +\n\u001b[0;32m--> 167\u001b[0;31m                                  ':' + function_name)\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown loss function:tanh"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='tanh', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.1 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/tensorflow-2.1-gpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
